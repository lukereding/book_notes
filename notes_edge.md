# on the edge

silver

this was an interesting and varied book, those various threads were held together by the idea of expected value (EV). the first half of the book was mostly about gambling and betting, which was interesting but less so than the second half of the book, which focused on use of EV and similar tools in other domains like business and philosophy, where EV plays a large role in determining ethical behavior for strict utilitarians.

as someone who thinks about EV a lot, a large part of the book reinforced how EVs can be overused and abused:


- one off vs repeated

Silver doesn't discuss risk premiums or 'risk aversion coefficients' and how they differ across people or decision domains. there's a lot of talk about EV+ bets or thinking about whether a one-off event is EV+, but how a decisoin-maker responds to such a situation really depends on the risk premium. for something like a bet, where you think it's likely that you'll have 100 similarly-sized EV+ bets, then it probably makes sense to take the EV+ bet. if there's just a single such bet, for most people such a bet will not make sense, depending. Silver doesn't really talk about any of that

- it’s a model, models are wrong

EV is really a model of the model. that model will be wrong. EVs are useful, but it is very easy to fall into the trap of meaningless precision that you'll never really be able to validate. for games like poker, where the probabilities of different cards appearing can be quantified, trusting the EV calculations is obviously more reasonable. but the second half of the book takes on EV is less defined domains (e.g., AI taking over the world) where a 'probability' just can't mean the same thing it does in the context of poker.

- sense of security with numbers

I think a big reason why people like using EVs is that it boils down a difficult question to a number. there's a veneer of cold-blooded math that can tell you what to do. it gives you a precise number that you can compare with other numbers. it feels neat and tidy.

of course any interesting decision in the real world isn't like that, and even if you _can_ compute some number that represents an EV, it doesn't mean it's useful or helpful or a substitute for using your brain.

- risk of ruin is high

related to the first point. for bets that aren't repeated, taking a single slightly EV+ bet is probably not a good idea if the potential loss is high, and there aren't opportunities to roll the die again to let the law of averages take over.

- doesn’t amend itself to the hardest questions or stuff that is difficult to quantify

the hardest questions are those that are least certain. uncertain things don't lend themselves well to quantifying probabilities. as we saw in the AI chapter, people have very different attitudes about p(doom), and it's unclear how to even think about validating or quantifying stuff like that without pulling a number out of thin air.

- tail risk / nonstationarity

if you asked someone what the probability was that we'd have little computers in our pockets 100 year ago, the question wouldn't have made any sense. we can't answer questions that we can't ask in the first place because the world will be different in the future. in particular, the world changes a lot, and not incremental change that we can see a long way off. sometimes there are step changes (e.g., smart phones, the internet) that change things fundamentally and just could not have been predicted. these are probably the most interesting and important realms to think about responding to, but the least able to be quantified by EV.